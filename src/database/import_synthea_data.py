#!/usr/bin/env python3
"""
Synthea Data Import Script for Clinical NLQ AI Assistant
Imports CSV data generated by Synthea into PostgreSQL database
"""

import os
import sys
import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
from sqlalchemy import create_engine
import logging
from datetime import datetime
import uuid

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('synthea_import.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SyntheaDataImporter:
    def __init__(self, db_config, csv_directory):
        """
        Initialize the Synthea data importer
        
        Args:
            db_config (dict): Database connection configuration
            csv_directory (str): Path to directory containing Synthea CSV files
        """
        self.db_config = db_config
        self.csv_directory = csv_directory
        self.engine = None
        self.connection = None
        
    def connect_to_database(self):
        """Establish database connection"""
        try:
            # Create SQLAlchemy engine with URL encoding for special characters
            from urllib.parse import quote_plus
            password_encoded = quote_plus(self.db_config['password'])
            connection_string = (
                f"postgresql://{self.db_config['user']}:{password_encoded}"
                f"@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            )
            self.engine = create_engine(connection_string)
            
            # Create psycopg2 connection for raw SQL operations
            self.connection = psycopg2.connect(**self.db_config)
            self.connection.autocommit = True
            
            logger.info("Successfully connected to PostgreSQL database")
            return True
            
        except Exception as e:
            logger.error(f"Failed to connect to database: {e}")
            return False
    
    def create_schema(self):
        """Create the database schema"""
        try:
            schema_file = os.path.join(os.path.dirname(__file__), 'schema.sql')
            with open(schema_file, 'r') as f:
                schema_sql = f.read()
            
            cursor = self.connection.cursor()
            
            # Execute schema creation with error handling for existing objects
            try:
                cursor.execute(schema_sql)
                logger.info("Database schema created successfully")
            except Exception as schema_error:
                if "already exists" in str(schema_error).lower():
                    logger.info("Database schema already exists, continuing...")
                else:
                    raise schema_error
            
            cursor.close()
            return True
            
        except Exception as e:
            logger.error(f"Failed to create schema: {e}")
            raise e
    
    def clean_dataframe(self, df, table_name):
        """Clean and prepare dataframe for database import"""
        logger.info(f"Cleaning data for table: {table_name}")
        
        # Convert column names to lowercase and replace spaces with underscores
        df.columns = df.columns.str.lower().str.replace(' ', '_')
        
        # Handle specific table transformations
        if table_name == 'patients':
            # Rename columns to match schema
            column_mapping = {
                'id': 'id',
                'birthdate': 'birth_date',
                'deathdate': 'death_date',
                'first': 'first_name',
                'middle': 'middle_name',
                'last': 'last_name',
                'suffix': 'suffix',
                'maiden': 'maiden_name',
                'marital': 'marital_status',
                'lat': 'latitude',
                'lon': 'longitude'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            date_columns = ['birth_date', 'death_date']
            for col in date_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce')
            
            # Convert numeric columns
            numeric_columns = ['healthcare_expenses', 'healthcare_coverage', 'income', 'latitude', 'longitude']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
        
        elif table_name == 'encounters':
            # Rename columns to match schema
            column_mapping = {
                'id': 'id',
                'start': 'start_time',
                'stop': 'stop_time',
                'patient': 'patient_id',
                'organization': 'organization_id',
                'provider': 'provider_id',
                'payer': 'payer_id',
                'encounterclass': 'encounter_class',
                'reasoncode': 'reason_code',
                'reasondescription': 'reason_description'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert timestamp columns
            timestamp_columns = ['start_time', 'stop_time']
            for col in timestamp_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce')
            
            # Convert numeric columns
            numeric_columns = ['base_encounter_cost', 'total_claim_cost', 'payer_coverage']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
        
        elif table_name == 'conditions':
            # Rename columns to match schema
            column_mapping = {
                'start': 'start_date',
                'stop': 'stop_date',
                'patient': 'patient_id',
                'encounter': 'encounter_id'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            date_columns = ['start_date', 'stop_date']
            for col in date_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
        
        elif table_name == 'medications':
            # Rename columns to match schema
            column_mapping = {
                'start': 'start_date',
                'stop': 'stop_date',
                'patient': 'patient_id',
                'payer': 'payer_id',
                'encounter': 'encounter_id',
                'reasoncode': 'reason_code',
                'reasondescription': 'reason_description'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            date_columns = ['start_date', 'stop_date']
            for col in date_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
            
            # Convert numeric columns
            numeric_columns = ['base_cost', 'payer_coverage', 'dispenses', 'total_cost']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
        
        elif table_name == 'procedures':
            # Rename columns to match schema
            column_mapping = {
                'date': 'date',
                'patient': 'patient_id',
                'encounter': 'encounter_id',
                'reasoncode': 'reason_code',
                'reasondescription': 'reason_description'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date
            
            # Convert numeric columns
            if 'base_cost' in df.columns:
                df['base_cost'] = pd.to_numeric(df['base_cost'], errors='coerce')
        
        elif table_name == 'observations':
            # Rename columns to match schema
            column_mapping = {
                'date': 'date',
                'patient': 'patient_id',
                'encounter': 'encounter_id'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date
        
        elif table_name == 'organizations':
            # Rename columns to match schema
            column_mapping = {
                'lat': 'latitude',
                'lon': 'longitude'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert numeric columns
            numeric_columns = ['latitude', 'longitude', 'revenue', 'utilization']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
        
        elif table_name == 'providers':
            # Rename columns to match schema
            column_mapping = {
                'organization': 'organization_id',
                'lat': 'latitude',
                'lon': 'longitude'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert numeric columns
            numeric_columns = ['latitude', 'longitude', 'utilization']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
        
        elif table_name == 'payers':
            # Convert numeric columns
            numeric_columns = ['amount_covered', 'amount_uncovered', 'revenue', 
                             'covered_encounters', 'uncovered_encounters', 'covered_medications',
                             'uncovered_medications', 'covered_procedures', 'uncovered_procedures',
                             'covered_immunizations', 'uncovered_immunizations', 'unique_customers',
                             'qols_avg', 'member_months']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
        
        elif table_name == 'immunizations':
            # Rename columns to match schema
            column_mapping = {
                'date': 'date',
                'patient': 'patient_id',
                'encounter': 'encounter_id'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date
            
            # Convert numeric columns
            if 'base_cost' in df.columns:
                df['base_cost'] = pd.to_numeric(df['base_cost'], errors='coerce')
        
        elif table_name == 'allergies':
            # Rename columns to match schema
            column_mapping = {
                'start': 'start_date',
                'stop': 'stop_date',
                'patient': 'patient_id',
                'encounter': 'encounter_id'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            date_columns = ['start_date', 'stop_date']
            for col in date_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
        
        elif table_name == 'care_plans':
            # Rename columns to match schema
            column_mapping = {
                'start': 'start_date',
                'stop': 'stop_date',
                'patient': 'patient_id',
                'encounter': 'encounter_id',
                'reasoncode': 'reason_code',
                'reasondescription': 'reason_description'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            date_columns = ['start_date', 'stop_date']
            for col in date_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
        
        elif table_name == 'devices':
            # Rename columns to match schema
            column_mapping = {
                'start': 'start_date',
                'stop': 'stop_date',
                'patient': 'patient_id',
                'encounter': 'encounter_id'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            date_columns = ['start_date', 'stop_date']
            for col in date_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
        
        elif table_name == 'supplies':
            # Rename columns to match schema
            column_mapping = {
                'date': 'date',
                'patient': 'patient_id',
                'encounter': 'encounter_id'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date
            
            # Convert numeric columns
            if 'quantity' in df.columns:
                df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')
        
        elif table_name == 'imaging_studies':
            # Rename columns to match schema
            column_mapping = {
                'date': 'date',
                'patient': 'patient_id',
                'encounter': 'encounter_id'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date
        
        elif table_name == 'payer_transitions':
            # Rename columns to match schema
            column_mapping = {
                'patient': 'patient_id',
                'start_year': 'start_date',
                'end_year': 'end_date',
                'payer': 'payer_id',
                'secondary_payer': 'secondary_payer_id'
            }
            df = df.rename(columns=column_mapping)
            
            # Convert date columns - these might be years, convert to dates
            date_columns = ['start_date', 'end_date']
            for col in date_columns:
                if col in df.columns:
                    # If it's a timestamp string, convert directly
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
        
        # Handle other tables similarly...
        
        # Replace NaN values with None for proper NULL handling
        df = df.where(pd.notnull(df), None)
        
        logger.info(f"Cleaned {len(df)} rows for {table_name}")
        return df
    
    def import_csv_file(self, csv_filename, table_name):
        """Import a single CSV file into the database"""
        csv_path = os.path.join(self.csv_directory, csv_filename)
        
        if not os.path.exists(csv_path):
            logger.warning(f"CSV file not found: {csv_path}")
            return False
        
        try:
            logger.info(f"Importing {csv_filename} into {table_name}")
            
            # Read CSV file
            df = pd.read_csv(csv_path)
            logger.info(f"Read {len(df)} rows from {csv_filename}")
            
            if len(df) == 0:
                logger.warning(f"No data found in {csv_filename}")
                return True
            
            # Clean the dataframe
            df = self.clean_dataframe(df, table_name)
            
            # Import to database using pandas to_sql
            df.to_sql(
                table_name, 
                self.engine, 
                schema='clinical_data',
                if_exists='append', 
                index=False,
                method='multi',
                chunksize=1000
            )
            
            logger.info(f"Successfully imported {len(df)} rows into {table_name}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to import {csv_filename}: {e}")
            return False
    
    def import_all_data(self):
        """Import all Synthea CSV files in the correct order"""
        
        # Define import order (respecting foreign key dependencies)
        import_order = [
            ('organizations.csv', 'organizations'),
            ('providers.csv', 'providers'),
            ('payers.csv', 'payers'),
            ('patients.csv', 'patients'),
            ('encounters.csv', 'encounters'),
            ('conditions.csv', 'conditions'),
            ('medications.csv', 'medications'),
            ('procedures.csv', 'procedures'),
            ('observations.csv', 'observations'),
            ('immunizations.csv', 'immunizations'),
            ('allergies.csv', 'allergies'),
            ('careplans.csv', 'care_plans'),
            ('devices.csv', 'devices'),
            ('supplies.csv', 'supplies'),
            ('imaging_studies.csv', 'imaging_studies'),
            ('claims.csv', 'claims'),
            ('claims_transactions.csv', 'claims_transactions'),
            ('payer_transitions.csv', 'payer_transitions')
        ]
        
        successful_imports = 0
        total_imports = len(import_order)
        
        for csv_file, table_name in import_order:
            if self.import_csv_file(csv_file, table_name):
                successful_imports += 1
            else:
                logger.warning(f"Skipping {csv_file} due to import failure")
        
        logger.info(f"Import completed: {successful_imports}/{total_imports} files imported successfully")
        return successful_imports == total_imports
    
    def create_indexes_and_constraints(self):
        """Create additional indexes and constraints after data import"""
        try:
            cursor = self.connection.cursor()
            
            # Additional indexes for performance
            additional_indexes = [
                "CREATE INDEX IF NOT EXISTS idx_encounters_date_range ON clinical_data.encounters USING btree (start_time, stop_time);",
                "CREATE INDEX IF NOT EXISTS idx_conditions_date_range ON clinical_data.conditions USING btree (start_date, stop_date);",
                "CREATE INDEX IF NOT EXISTS idx_medications_date_range ON clinical_data.medications USING btree (start_date, stop_date);",
                "CREATE INDEX IF NOT EXISTS idx_observations_value ON clinical_data.observations USING btree (value) WHERE value IS NOT NULL;",
                "CREATE INDEX IF NOT EXISTS idx_patients_age ON clinical_data.patients USING btree (clinical_data.calculate_age(birth_date));",
            ]
            
            for index_sql in additional_indexes:
                cursor.execute(index_sql)
                logger.info(f"Created index: {index_sql.split('idx_')[1].split(' ')[0]}")
            
            cursor.close()
            logger.info("Additional indexes created successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to create additional indexes: {e}")
            return False
    
    def generate_summary_statistics(self):
        """Generate and log summary statistics of imported data"""
        try:
            cursor = self.connection.cursor()
            
            # Get row counts for all tables
            tables = [
                'patients', 'organizations', 'providers', 'payers', 'encounters',
                'conditions', 'medications', 'procedures', 'observations',
                'immunizations', 'allergies', 'care_plans', 'devices', 'supplies'
            ]
            
            logger.info("=== DATA IMPORT SUMMARY ===")
            
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM clinical_data.{table}")
                count = cursor.fetchone()[0]
                logger.info(f"{table.upper()}: {count:,} records")
            
            # Additional statistics
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_patients,
                    COUNT(CASE WHEN death_date IS NULL THEN 1 END) as living_patients,
                    COUNT(CASE WHEN death_date IS NOT NULL THEN 1 END) as deceased_patients,
                    ROUND(AVG(clinical_data.calculate_age(birth_date)), 1) as avg_age
                FROM clinical_data.patients
            """)
            
            stats = cursor.fetchone()
            logger.info(f"PATIENT STATISTICS:")
            logger.info(f"  Total: {stats[0]:,}")
            logger.info(f"  Living: {stats[1]:,}")
            logger.info(f"  Deceased: {stats[2]:,}")
            logger.info(f"  Average Age: {stats[3]} years")
            
            cursor.close()
            logger.info("=== END SUMMARY ===")
            
        except Exception as e:
            logger.error(f"Failed to generate summary statistics: {e}")
    
    def close_connections(self):
        """Close database connections"""
        if self.connection:
            self.connection.close()
        if self.engine:
            self.engine.dispose()
        logger.info("Database connections closed")

def main():
    """Main function to run the data import"""
    
    # Database configuration
    db_config = {
        'host': 'localhost',
        'port': 5432,
        'database': 'medical',
        'user': 'postgres',
        'password': 'Pass@123'
    }
    
    # CSV directory path
    csv_directory = r'd:\projects\healthca\output\csv'
    
    # Create importer instance
    importer = SyntheaDataImporter(db_config, csv_directory)
    
    try:
        # Connect to database
        if not importer.connect_to_database():
            logger.error("Failed to connect to database. Exiting.")
            return False
        
        # Create schema (skip if already exists)
        try:
            importer.create_schema()
        except Exception as e:
            if "already exists" in str(e):
                logger.info("Database schema already exists, continuing with data import...")
            else:
                logger.error(f"Failed to create database schema: {e}")
                return False
        
        # Import all data
        if not importer.import_all_data():
            logger.warning("Some data imports failed, but continuing...")
        
        # Create additional indexes
        importer.create_indexes_and_constraints()
        
        # Generate summary statistics
        importer.generate_summary_statistics()
        
        logger.info("Data import process completed successfully!")
        return True
        
    except Exception as e:
        logger.error(f"Unexpected error during import: {e}")
        return False
        
    finally:
        importer.close_connections()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)